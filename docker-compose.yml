services:
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION (24 cores, 32GB total - OPTIMIZED FOR 20K USERS)
    # ==============================================
    cpus: '8.0' # 33% CPU - High concurrent database operations
    mem_limit: '12g' # 37.5% RAM - Large connection pool & cache

    command: ['postgres', '-c', 'config_file=/etc/postgresql/postgresql.conf']
    env_file: [.env.docker]
    ports:
      - '127.0.0.1:${POSTGRES_PORT:-5432}:5432'
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST_AUTH_METHOD=${POSTGRES_HOST_AUTH_METHOD}
      - POSTGRES_INITDB_ARGS=${POSTGRES_INITDB_ARGS}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    networks: [app-network]
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-shopsifu}']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION (OPTIMIZED FOR 20K USERS)
    # ==============================================
    cpus: '4.0' # 16.7% CPU - High frequency cache operations
    mem_limit: '8g' # 25% RAM - Large cache storage for high concurrency

    command: ['redis-server', '/usr/local/etc/redis/redis.conf']
    env_file: [.env.docker]
    ports:
      - '127.0.0.1:${REDIS_PORT:-6379}:6379'
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks: [app-network]
    healthcheck:
      test: ['CMD-SHELL', 'redis-cli -a "$${REDIS_PASSWORD}" ping | grep -q PONG']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: elasticsearch
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION (OPTIMIZED FOR 20K USERS)
    # ==============================================
    cpus: '3.0' # 12.5% CPU - High frequency search operations
    mem_limit: '6g' # 18.75% RAM - Large search index & cache

    env_file: [.env.docker]
    environment:
      - node.name=${ELASTICSEARCH_NODE_NAME}
      - cluster.name=${ELASTICSEARCH_CLUSTER_NAME}
      - discovery.type=${ELASTICSEARCH_DISCOVERY_TYPE}
      - bootstrap.memory_lock=false
      - ELASTICSEARCH_HEAP_SIZE=2g
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - xpack.security.enabled=true
      - xpack.security.enrollment.enabled=true
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD}
      - node.store.allow_mmap=false
      - indices.memory.index_buffer_size=20%
      - xpack.ml.enabled=false
      - ingest.geoip.downloader.enabled=false
      - action.destructive_requires_name=true
    ulimits:
      nofile: { soft: 65536, hard: 65536 }
    ports:
      - '127.0.0.1:${ELASTICSEARCH_PORT:-9200}:9200'
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks: [app-network]
    healthcheck:
      test:
        ['CMD-SHELL', 'curl -fsS -m 5 -u elastic:$${ELASTICSEARCH_PASSWORD} http://localhost:9200 >/dev/null || exit 1']
      interval: 30s
      timeout: 15s
      retries: 10
      start_period: 120s

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: kibana
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION
    # ==============================================
    cpus: '0.5' # 2.5% CPU - UI operations
    mem_limit: '1g' # 3% RAM - UI rendering

    env_file: [.env.docker]
    environment:
      - SERVER_NAME=${KIBANA_SERVER_NAME}
      - ELASTICSEARCH_HOSTS=${KIBANA_ELASTICSEARCH_HOSTS}
      - ELASTICSEARCH_USERNAME=${KIBANA_ELASTICSEARCH_USERNAME}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
      - SERVER_SSL_ENABLED=${KIBANA_SERVER_SSL_ENABLED}
      - XPACK_SECURITY_ENABLED=${KIBANA_XPACK_SECURITY_ENABLED}
    ports:
      - '127.0.0.1:${KIBANA_PORT:-5601}:5601'
    volumes:
      - ./certs:/usr/share/kibana/config/certs:ro
      - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    networks: [app-network]
    depends_on:
      elasticsearch: { condition: service_healthy }
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'curl -fsS -u kibana_system:$${ELASTICSEARCH_PASSWORD} http://localhost:5601/api/status | grep -q kibana'
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  server:
    image: ${SERVER_IMAGE:-server-shopsifu:latest}
    build:
      context: .
      dockerfile: Dockerfile
    container_name: server
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION (MAIN APPLICATION)
    # ==============================================
    cpus: '12.0' # 60% CPU - Main application logic
    mem_limit: '20g' # 62.5% RAM - Application memory & cache

    # ==============================================
    # SYSTEM OPTIMIZATION FOR HIGH TRAFFIC
    # ==============================================
    ulimits:
      nofile: 1048576 # 1M file descriptors for high concurrency
      nproc: 65536 # High process limit
      core: 0 # Disable core dumps in production

    # ==============================================
    # GRACEFUL SHUTDOWN
    # ==============================================
    stop_grace_period: 60s # Allow graceful shutdown for long-running requests

    # ==============================================
    # NETWORK & PORTS
    # ==============================================
    ports:
      - '${SERVER_PORT:-3000}:3000'

    # ==============================================
    # ENVIRONMENT CONFIGURATION (PURE DOCKER)
    # ==============================================
    env_file: .env.docker
    environment:
      # Node.js Performance Optimization (OPTIMIZED FOR 20K USERS)
      - NODE_ENV=production
      - PORT=3000
      - UV_THREADPOOL_SIZE=96 # 24 cores Ã— 4 threads per core
      - NODE_OPTIONS=--max-old-space-size=24000 # 24GB heap size

      # Application Configuration (OPTIMIZED FOR 20K USERS)
      - APP_WORKERS=24 # 24 worker processes (1 per core)
      - APP_CONCURRENT_REQUESTS=5000 # Ultra high concurrency support

      # Database Connection Pool (OPTIMIZED FOR 20K USERS)
      - DB_POOL_MIN=50
      - DB_POOL_MAX=200

      # Redis Connection Pool (OPTIMIZED FOR 20K USERS)
      - REDIS_POOL_MIN=20
      - REDIS_POOL_MAX=100

      # External API Secrets (from GitHub Secrets)
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - PAYMENT_API_KEY=${PAYMENT_API_KEY}
      - VNPAY_TMN_CODE=${VNPAY_TMN_CODE}
      - VNPAY_SECURE_SECRET=${VNPAY_SECURE_SECRET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - RESEND_API_KEY=${RESEND_API_KEY}
      - SENTRY_DSN=${SENTRY_DSN}

    # ==============================================
    # NETWORKING
    # ==============================================
    networks: [app-network]

    # ==============================================
    # VOLUMES & STORAGE
    # ==============================================
    volumes:
      - ./logs:/app/logs # Application logs
      - ./certs:/app/certs # SSL certificates
      - ./upload:/app/upload # User uploads

    # ==============================================
    # TEMPORARY STORAGE (RAM-based for performance)
    # ==============================================
    tmpfs:
      - /tmp:size=2g # 2GB RAM for temp files
      - /app/temp:size=1g # 1GB RAM for app temp files

    # ==============================================
    # DEPENDENCIES
    # ==============================================
    depends_on:
      postgres: { condition: service_healthy }
      redis: { condition: service_healthy }
      elasticsearch: { condition: service_healthy }

    # ==============================================
    # HEALTH MONITORING
    # ==============================================
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:3000/health || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION
    # ==============================================
    cpus: '0.5' # 2.5% CPU - Metrics collection
    mem_limit: '1g' # 3% RAM - Metrics storage

    env_file: [.env.docker]
    ports:
      - '127.0.0.1:${PROMETHEUS_PORT:-9090}:9090'
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=${PROMETHEUS_RETENTION_DAYS:-7}d'
      - '--web.enable-lifecycle=${PROMETHEUS_WEB_ENABLE_LIFECYCLE}'
      - '--web.enable-admin-api=${PROMETHEUS_WEB_ENABLE_ADMIN_API}'
      - '--web.enable-telemetry=${PROMETHEUS_WEB_ENABLE_TELEMETRY}'
    networks: [app-network]
    depends_on: [server]
    healthcheck:
      test: ['CMD-SHELL', 'wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  grafana:
    image: grafana/grafana:11.4.0
    container_name: grafana
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION
    # ==============================================
    cpus: '0.5' # 2.5% CPU - Dashboard rendering
    mem_limit: '1g' # 3% RAM - Dashboard cache

    env_file: [.env.docker]
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=${GRAFANA_ALLOW_SIGNUP}
      - GF_AUTH_ANONYMOUS_ENABLED=${GRAFANA_ANONYMOUS_ENABLED}
      - GF_SERVER_HTTP_PORT=${GRAFANA_SERVER_HTTP_PORT}
      - GF_SECURITY_DISABLE_GRAVATAR=${GRAFANA_SECURITY_DISABLE_GRAVATAR}
      - GF_SECURITY_COOKIE_SECURE=${GRAFANA_SECURITY_COOKIE_SECURE}
      - GF_SECURITY_COOKIE_HTTPONLY=${GRAFANA_SECURITY_COOKIE_HTTPONLY}
    ports:
      - '127.0.0.1:${GRAFANA_PORT:-3001}:3000'
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ./config/grafana.ini:/etc/grafana/grafana.ini:ro
    networks: [app-network]
    depends_on:
      prometheus: { condition: service_healthy }
    healthcheck:
      test: ['CMD-SHELL', 'wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  pgbouncer:
    image: edoburu/pgbouncer:1.18.0
    container_name: pgbouncer
    restart: unless-stopped

    # ==============================================
    # RESOURCE ALLOCATION (OPTIMIZED FOR 20K USERS)
    # ==============================================
    cpus: '2.0' # 8.3% CPU - High frequency connection management
    mem_limit: '3g' # 9.375% RAM - Large connection pool management

    ports:
      - '127.0.0.1:${PGBOUNCER_PORT:-6432}:6432'
    volumes:
      - ./config/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ./config/userlist.txt:/etc/pgbouncer/userlist.txt:ro
    networks: [app-network]
    depends_on:
      postgres: { condition: service_healthy }
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -p 6432 -U shopsifu']
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

networks:
  app-network:
    driver: bridge
    name: app-network
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
    name: postgres-data
  redis_data:
    driver: local
    name: redis-data
  esdata:
    driver: local
    name: elasticsearch-data
  prometheus_data:
    driver: local
    name: prometheus-data
  grafana_data:
    driver: local
    name: grafana-data
